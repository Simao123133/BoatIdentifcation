%Generate Narxnet open loop prediction from data
clear
load('raw_data.mat')
start = 1;
finish = 1 + 800/0.1;
ua = medfilt1(U.signals.values(start:finish),10);
wa = medfilt1(W.signals.values(start:finish),10);
qa = medfilt1(gyrY.signals.values(start:finish),50);
pitcha = medfilt1(Pitch.signals.values(start:finish),10);
za = medfilt1(Height.signals.values(start:finish),10);
va = medfilt1(V.signals.values(start:finish),10);
pa = medfilt1(gyrX.signals.values(start:finish),50);
ra = medfilt1(gyrZ.signals.values(start:finish),50);
rolla = medfilt1(Roll.signals.values(start:finish),10);
LFa = Left_foil.signals.values(start:finish);
RFa = Right_foil.signals.values(start:finish);
ReFa = Rear_foil.signals.values(start:finish);
Rpmsa = medfilt1(Motor.signals.values(start:finish),10);
Ruddera = medfilt1(Rudder.signals.values(start:finish),10);
load('raw_data_montargil.mat')
start = 1;
finish = 36000/01;
um = medfilt1(U.signals.values(start:finish),10);
wm = medfilt1(W.signals.values(start:finish),10);
qm = medfilt1(gyrY.signals.values(start:finish),50);
pitchm = medfilt1(Pitch.signals.values(start:finish),10);
zm = medfilt1(Height.signals.values(start:finish),10);
vm = medfilt1(V.signals.values(start:finish),10);
pm = medfilt1(gyrX.signals.values(start:finish),50);
rm = medfilt1(gyrZ.signals.values(start:finish),50);
rollm = medfilt1(Roll.signals.values(start:finish),10);
LFm = Left_foil.signals.values(start:finish);
RFm = Right_foil.signals.values(start:finish);
ReFm = Rear_foil.signals.values(start:finish);
Rpmsm = medfilt1(Motor.signals.values(start:finish),10);
Rudderm = medfilt1(Rudder.signals.values(start:finish),10);

splitm = round((finish-start)/2);

u = [ua;um];
w = [wa;wm];
q = [qa;qm];
pitch = [pitcha;pitchm];
z = [za;zm];
v = [va;vm];
p = [pa;pm];
r = [ra;rm];
roll = [rolla;rollm];
LF = [LFa;LFm];
RF = [RFa;RFm];
Rudder = [Ruddera;Rudderm];
Rpms = [Rpmsa;Rpmsm];

inputs = [LFm(1:splitm),RFm(1:splitm),Rudderm(1:splitm),Rpmsm(1:splitm)];
outputs = [um(1:splitm),wm(1:splitm),qm(1:splitm),pitchm(1:splitm),zm(1:splitm),vm(1:splitm),pm(1:splitm),rm(1:splitm),rollm(1:splitm)];
t = 0:0.1:length(LFm(1:splitm))/10-0.1;


titles = ["u",'w','dpitch','pitch','z','v','droll','dyaw','roll'];
figure(1)
for i=1:9
subplot(3,3,i)
plot(t,outputs(:,i));
title(titles(i))
end
% Solve an Autoregression Problem with External Input with a NARX Neural Network
% Script generated by Neural Time Series app
% Created 22-Nov-2021 17:46:54
%
% This script assumes these variables are defined:
%
%   inputs - input time series.
%   outputs - feedback time series.

X = tonndata(inputs,false,false);
T = tonndata(outputs,false,false);

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainlm';  % Levenberg-Marquardt backpropagation.

% Create a Nonlinear Autoregressive Network with External Input
inputDelays = 1;
feedbackDelays = 1;
hiddenLayerSize = 20;
net = narxnet(inputDelays,feedbackDelays,hiddenLayerSize,'closed',trainFcn);

% Prepare the Data for Training and Simulation
% The function PREPARETS prepares timeseries data for a particular network,
% shifting time by the minimum amount to fill input states and layer
% states. Using PREPARETS allows you to keep your original time series data
% unchanged, while easily customizing it for networks with differing
% numbers of delays, with open loop or closed loop feedback modes.
[x,xi,ai,t] = preparets(net,X,{},T);

% Setup Division of Data for Training, Validation, Testing
net.divideParam.trainRatio = 70/100;
net.divideParam.valRatio = 15/100;
net.divideParam.testRatio = 15/100;
net.divideFcn = 'divideblock';
net.sampleTime = 0.1;

% Train the Network
[net,tr] = train(net,x,t,xi,ai);
% Step-Ahead Prediction Network
% For some applications it helps to get the prediction a timestep early.
% The original network returns predicted y(t+1) at the same time it is
% given y(t+1). For some applications such as decision making, it would
% help to have predicted y(t+1) once y(t) is available, but before the
% actual y(t+1) occurs. The network can be made to return its output a
% timestep early by removing one delay so that its minimal tap delay is now
% 0 instead of 1. The new network returns the same outputs as the original
% network, but outputs are shifted left one timestep.

time = 0:0.1:length(LFm(splitm:end))/10-0.1;
inputsm = [LFm(splitm:end),RFm(splitm:end),Rudderm(splitm:end),Rpmsm(splitm:end)];
outputsm = [um(splitm:end),wm(splitm:end),qm(splitm:end),pitchm(splitm:end),zm(splitm:end),vm(splitm:end),pm(splitm:end),rm(splitm:end),rollm(splitm:end)];
for i=1:length(outputsm)
    xm(1:2,i) = {inputsm(i,:)';outputsm(i,:)'};
end
%y = net(xm,xm(:,1),ai);
start = 120;
finish = 140;
X = tonndata(inputsm(start:finish,:),false,false);
T = tonndata(outputsm(start:finish,:),false,false);
[xc,xic,aic,tc] = preparets(net,X,{},T);
y = net(xc,xic,aic);

res = zeros(finish-start,9);
figure(2)
for i=1:9
subplot(3,3,i);
for j=1:length(y)
    what = y{j};
    res(j,i) = what(i);
end
plot(time(start:finish-1),res(1:finish-start,i),time(start:finish-1),outputsm(start+1:finish,i));
title(titles(i))
legend('NN','Real') 
end

for i=1:9
   MSE(i) =  sum((res(1:finish-start,i) - outputsm(start+1:finish,i)).^2)/length(time);
end



